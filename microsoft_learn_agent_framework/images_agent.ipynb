{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d90248",
   "metadata": {},
   "source": [
    "## 1. Importaciones y Configuraci√≥n\n",
    "\n",
    "Importamos las clases necesarias para trabajar con contenido multimodal:\n",
    "- **ChatMessage**: Contenedor de mensajes\n",
    "- **TextContent**: Para texto\n",
    "- **DataContent**: Para datos binarios (im√°genes)\n",
    "- **Role**: Roles de los participantes (USER, ASSISTANT)\n",
    "- **Path**: Para manejo de rutas de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41188fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from agent_framework import ChatMessage, TextContent, DataContent, Role\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Importaciones completadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128aa413",
   "metadata": {},
   "source": [
    "## 2. Creaci√≥n del Agente de Visi√≥n\n",
    "\n",
    "### Configuraci√≥n del Agente:\n",
    "\n",
    "El agente de visi√≥n requiere:\n",
    "- **Modelo compatible**: GPT-4 Vision (gpt-4o, gpt-4-vision, etc.)\n",
    "- **Instructions**: Gu√≠a sobre c√≥mo analizar im√°genes\n",
    "- **Credential**: Autenticaci√≥n con Azure\n",
    "\n",
    "### Importante:\n",
    "- Aseg√∫rate de que tu deployment en Azure OpenAI sea de un modelo con capacidades de visi√≥n\n",
    "- Los modelos GPT-3.5 no soportan an√°lisis de im√°genes\n",
    "- GPT-4o y GPT-4 Vision son las opciones recomendadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6506c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AzureOpenAIChatClient(\n",
    "    credential=AzureCliCredential(),\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    deployment_name=os.getenv(\"MODEL\"),  # Debe ser un modelo con capacidades de visi√≥n\n",
    ").create_agent(\n",
    "    name=\"VisionAgent\",\n",
    "    instructions=\"Eres un agente √∫til que puede analizar im√°genes con gran detalle.\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente de visi√≥n creado\")\n",
    "print(f\"ü§ñ Modelo: {os.getenv('MODEL')}\")\n",
    "print(\"üëÅÔ∏è  Capacidad: An√°lisis de im√°genes y texto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44360ee6",
   "metadata": {},
   "source": [
    "## 3. Carga de Imagen desde Archivo Local\n",
    "\n",
    "### Proceso de Carga:\n",
    "\n",
    "1. **Ubicar la imagen**: Usar Path para construir la ruta de forma portable\n",
    "2. **Leer como binario**: Abrir en modo 'rb' (read binary)\n",
    "3. **Almacenar bytes**: Los datos binarios se pasan al agente\n",
    "\n",
    "### Formatos Soportados:\n",
    "- JPEG (.jpg, .jpeg)\n",
    "- PNG (.png)\n",
    "- GIF (.gif)\n",
    "- WebP (.webp)\n",
    "\n",
    "### Consideraciones:\n",
    "- Tama√±o m√°ximo: T√≠picamente 20MB\n",
    "- Resoluci√≥n: Mayor calidad = mejor an√°lisis (pero m√°s tokens)\n",
    "- Costo: Im√°genes de alta resoluci√≥n consumen m√°s tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85bb177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir la ruta al archivo de imagen\n",
    "script_dir = Path(\".\")  # Directorio actual (notebook)\n",
    "img_path = script_dir / \"images\" / \"Goku.jpg\"\n",
    "\n",
    "print(f\"üìÇ Buscando imagen en: {img_path}\")\n",
    "\n",
    "# Verificar si el archivo existe\n",
    "if img_path.exists():\n",
    "    print(f\"‚úÖ Imagen encontrada\")\n",
    "    \n",
    "    # Leer la imagen como bytes\n",
    "    with open(img_path, \"rb\") as f:\n",
    "        image_bytes = f.read()\n",
    "    \n",
    "    # Mostrar informaci√≥n sobre la imagen\n",
    "    print(f\"üìä Tama√±o del archivo: {len(image_bytes) / 1024:.2f} KB\")\n",
    "else:\n",
    "    print(\"‚ùå Imagen no encontrada. Aseg√∫rate de que el archivo existe.\")\n",
    "    print(f\"   Ruta esperada: {img_path.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f6219",
   "metadata": {},
   "source": [
    "## 4. Construcci√≥n del Mensaje Multimodal\n",
    "\n",
    "### Estructura del Mensaje:\n",
    "\n",
    "Un `ChatMessage` multimodal contiene:\n",
    "- **role**: Qui√©n env√≠a el mensaje (USER, ASSISTANT, SYSTEM)\n",
    "- **contents**: Lista de contenidos de diferentes tipos\n",
    "\n",
    "### Tipos de Contenido:\n",
    "\n",
    "1. **TextContent**: \n",
    "   - Contiene la pregunta o instrucci√≥n\n",
    "   - Se especifica con `text=...`\n",
    "\n",
    "2. **DataContent**: \n",
    "   - Contiene los datos binarios de la imagen\n",
    "   - Requiere `data=...` (bytes)\n",
    "   - Requiere `media_type=...` (ej: \"image/jpeg\", \"image/png\")\n",
    "\n",
    "### Media Types Comunes:\n",
    "- `image/jpeg` - Para archivos .jpg o .jpeg\n",
    "- `image/png` - Para archivos .png\n",
    "- `image/gif` - Para archivos .gif\n",
    "- `image/webp` - Para archivos .webp\n",
    "\n",
    "### Orden de Contenidos:\n",
    "El orden puede ser importante:\n",
    "- Texto primero + Imagen: \"Analiza esta imagen...\"\n",
    "- Imagen primero + Texto: \"[Imagen] ¬øQu√© ves aqu√≠?\"\n",
    "\n",
    "Ambos funcionan, pero el primero suele ser m√°s natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b598403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir mensaje con texto e imagen\n",
    "message = ChatMessage(\n",
    "    role=Role.USER,\n",
    "    contents=[\n",
    "        TextContent(text=\"¬øQu√© ves en esta imagen? Describe detalladamente.\"),\n",
    "        DataContent(\n",
    "            data=image_bytes,\n",
    "            media_type=\"image/jpeg\"  # Especificar el tipo MIME correcto\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Mensaje multimodal construido\")\n",
    "print(f\"üìù Componentes del mensaje:\")\n",
    "print(f\"   - Texto: '{message.contents[0].text}'\")\n",
    "print(f\"   - Imagen: {len(image_bytes)} bytes, tipo: {message.contents[1].media_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab820751",
   "metadata": {},
   "source": [
    "## 5. Env√≠o del Mensaje y Obtenci√≥n de Respuesta\n",
    "\n",
    "### Proceso de An√°lisis:\n",
    "\n",
    "1. El agente recibe el mensaje multimodal\n",
    "2. El modelo procesa la imagen y el texto\n",
    "3. Genera una descripci√≥n basada en la comprensi√≥n visual\n",
    "4. Retorna la respuesta en formato de texto\n",
    "\n",
    "### Tiempos de Respuesta:\n",
    "- Im√°genes peque√±as: 2-5 segundos\n",
    "- Im√°genes grandes: 5-15 segundos\n",
    "- Depende de la complejidad de la consulta\n",
    "\n",
    "### Calidad del An√°lisis:\n",
    "- El modelo puede identificar objetos, personas, escenas\n",
    "- Reconoce texto visible en la imagen (OCR b√°sico)\n",
    "- Detecta colores, emociones, composici√≥n\n",
    "- Puede hacer inferencias sobre contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviar mensaje al agente y obtener respuesta\n",
    "print(\"üöÄ Enviando imagen al agente para an√°lisis...\\n\")\n",
    "\n",
    "response = asyncio.run(agent.run(message))\n",
    "\n",
    "print(\"üí¨ Respuesta del agente:\")\n",
    "print(\"=\" * 80)\n",
    "print(response.text)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af5e39d",
   "metadata": {},
   "source": [
    "## 6. Consultas Adicionales sobre la Misma Imagen\n",
    "\n",
    "Podemos hacer m√∫ltiples preguntas sobre la misma imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40241e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregunta espec√≠fica sobre colores\n",
    "async def ask_about_colors():\n",
    "    message = ChatMessage(\n",
    "        role=Role.USER,\n",
    "        contents=[\n",
    "            TextContent(text=\"¬øQu√© colores predominan en la imagen?\"),\n",
    "            DataContent(data=image_bytes, media_type=\"image/jpeg\")\n",
    "        ]\n",
    "    )\n",
    "    response = await agent.run(message)\n",
    "    print(\"üé® An√°lisis de colores:\")\n",
    "    print(response.text)\n",
    "    print()\n",
    "\n",
    "await ask_about_colors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3385f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregunta sobre el estado emocional\n",
    "async def ask_about_emotion():\n",
    "    message = ChatMessage(\n",
    "        role=Role.USER,\n",
    "        contents=[\n",
    "            TextContent(text=\"¬øQu√© emociones o energ√≠a transmite el personaje?\"),\n",
    "            DataContent(data=image_bytes, media_type=\"image/jpeg\")\n",
    "        ]\n",
    "    )\n",
    "    response = await agent.run(message)\n",
    "    print(\"üòä An√°lisis emocional:\")\n",
    "    print(response.text)\n",
    "    print()\n",
    "\n",
    "await ask_about_emotion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ad221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificaci√≥n de contexto\n",
    "async def ask_about_context():\n",
    "    message = ChatMessage(\n",
    "        role=Role.USER,\n",
    "        contents=[\n",
    "            TextContent(text=\"¬øReconoces a este personaje? ¬øDe qu√© anime o manga es?\"),\n",
    "            DataContent(data=image_bytes, media_type=\"image/jpeg\")\n",
    "        ]\n",
    "    )\n",
    "    response = await agent.run(message)\n",
    "    print(\"üé≠ Identificaci√≥n de personaje:\")\n",
    "    print(response.text)\n",
    "    print()\n",
    "\n",
    "await ask_about_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c84ab4",
   "metadata": {},
   "source": [
    "## 7. An√°lisis de M√∫ltiples Im√°genes\n",
    "\n",
    "Tambi√©n podemos analizar m√∫ltiples im√°genes en un solo mensaje para comparaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1cae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n auxiliar para analizar m√∫ltiples im√°genes\n",
    "async def compare_images(img_paths, question):\n",
    "    \"\"\"\n",
    "    Analiza m√∫ltiples im√°genes y responde una pregunta sobre ellas.\n",
    "    \n",
    "    Args:\n",
    "        img_paths: Lista de rutas a las im√°genes\n",
    "        question: Pregunta sobre las im√°genes\n",
    "    \"\"\"\n",
    "    contents = [TextContent(text=question)]\n",
    "    \n",
    "    # Cargar cada imagen y agregarla al mensaje\n",
    "    for img_path in img_paths:\n",
    "        if Path(img_path).exists():\n",
    "            with open(img_path, \"rb\") as f:\n",
    "                img_bytes = f.read()\n",
    "            \n",
    "            # Detectar tipo MIME basado en extensi√≥n\n",
    "            ext = Path(img_path).suffix.lower()\n",
    "            media_type = {\n",
    "                '.jpg': 'image/jpeg',\n",
    "                '.jpeg': 'image/jpeg',\n",
    "                '.png': 'image/png',\n",
    "                '.gif': 'image/gif',\n",
    "                '.webp': 'image/webp'\n",
    "            }.get(ext, 'image/jpeg')\n",
    "            \n",
    "            contents.append(DataContent(data=img_bytes, media_type=media_type))\n",
    "    \n",
    "    message = ChatMessage(role=Role.USER, contents=contents)\n",
    "    response = await agent.run(message)\n",
    "    return response.text\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de comparaci√≥n de im√°genes definida\")\n",
    "print(\"üí° Uso: await compare_images(['img1.jpg', 'img2.jpg'], '¬øEn qu√© se parecen?')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e566c",
   "metadata": {},
   "source": [
    "## 8. Casos de Uso Avanzados\n",
    "\n",
    "### OCR (Reconocimiento de Texto)\n",
    "Extraer texto visible en im√°genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a868ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_text_from_image(img_path):\n",
    "    \"\"\"\n",
    "    Extrae texto de una imagen usando el agente de visi√≥n.\n",
    "    √ötil para documentos, capturas de pantalla, letreros, etc.\n",
    "    \"\"\"\n",
    "    with open(img_path, \"rb\") as f:\n",
    "        img_bytes = f.read()\n",
    "    \n",
    "    message = ChatMessage(\n",
    "        role=Role.USER,\n",
    "        contents=[\n",
    "            TextContent(text=\"Extrae todo el texto visible en esta imagen. Mant√©n el formato original.\"),\n",
    "            DataContent(data=img_bytes, media_type=\"image/jpeg\")\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    response = await agent.run(message)\n",
    "    return response.text\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de OCR definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22100cd8",
   "metadata": {},
   "source": [
    "### An√°lisis de Documentos\n",
    "Interpretar gr√°ficos, diagramas o tablas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9970f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def analyze_chart(img_path):\n",
    "    \"\"\"\n",
    "    Analiza gr√°ficos, diagramas o visualizaciones de datos.\n",
    "    El agente puede interpretar tendencias, valores y patrones.\n",
    "    \"\"\"\n",
    "    with open(img_path, \"rb\") as f:\n",
    "        img_bytes = f.read()\n",
    "    \n",
    "    message = ChatMessage(\n",
    "        role=Role.USER,\n",
    "        contents=[\n",
    "            TextContent(text=\"Analiza este gr√°fico. Describe qu√© datos muestra, tendencias principales y conclusiones.\"),\n",
    "            DataContent(data=img_bytes, media_type=\"image/png\")\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    response = await agent.run(message)\n",
    "    return response.text\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de an√°lisis de gr√°ficos definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31bb566",
   "metadata": {},
   "source": [
    "## 9. Mejores Pr√°cticas y Optimizaci√≥n\n",
    "\n",
    "### Tips para Mejores Resultados:\n",
    "\n",
    "1. **Calidad de Imagen**:\n",
    "   - Usa im√°genes claras y bien iluminadas\n",
    "   - Evita im√°genes borrosas o de muy baja resoluci√≥n\n",
    "   - Formato JPEG o PNG son ideales\n",
    "\n",
    "2. **Tama√±o de Imagen**:\n",
    "   - Recomendado: 512x512 a 2048x2048 p√≠xeles\n",
    "   - Im√°genes m√°s grandes = m√°s tokens = mayor costo\n",
    "   - El modelo redimensiona autom√°ticamente si es necesario\n",
    "\n",
    "3. **Preguntas Espec√≠ficas**:\n",
    "   - S√© espec√≠fico en lo que quieres saber\n",
    "   - \"Describe los colores\" vs \"¬øQu√© ves?\"\n",
    "   - Preguntas claras = respuestas m√°s precisas\n",
    "\n",
    "4. **Manejo de Errores**:\n",
    "   ```python\n",
    "   try:\n",
    "       response = await agent.run(message)\n",
    "   except Exception as e:\n",
    "       print(f\"Error al analizar imagen: {e}\")\n",
    "   ```\n",
    "\n",
    "5. **Cach√© de Resultados**:\n",
    "   - Guarda respuestas para evitar re-an√°lisis\n",
    "   - Usa hash de imagen como clave\n",
    "   - Ahorra costos y tiempo\n",
    "\n",
    "### Limitaciones a Considerar:\n",
    "\n",
    "1. **Contenido Sensible**:\n",
    "   - El modelo puede rechazar analizar contenido inapropiado\n",
    "   - Tiene filtros de seguridad integrados\n",
    "\n",
    "2. **Precisi√≥n**:\n",
    "   - No es perfecto para OCR de documentos complejos\n",
    "   - Puede tener alucinaciones (inventar detalles)\n",
    "   - Verifica informaci√≥n cr√≠tica\n",
    "\n",
    "3. **Idioma**:\n",
    "   - Funciona mejor en ingl√©s\n",
    "   - Espa√±ol funciona bien pero puede variar\n",
    "   - Puedes especificar idioma de respuesta en instrucciones\n",
    "\n",
    "4. **Costos**:\n",
    "   - Im√°genes consumen significativamente m√°s tokens que texto\n",
    "   - Alta resoluci√≥n = m√°s tokens\n",
    "   - Monitorea uso para controlar costos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc5c3d",
   "metadata": {},
   "source": [
    "## 10. An√°lisis y Conclusiones\n",
    "\n",
    "### Capacidades Demostradas:\n",
    "\n",
    "1. **An√°lisis Visual Completo**:\n",
    "   - Identificaci√≥n de objetos y escenas\n",
    "   - Descripci√≥n detallada de im√°genes\n",
    "   - Reconocimiento de contexto\n",
    "\n",
    "2. **Multimodalidad**:\n",
    "   - Combinar texto e im√°genes en mensajes\n",
    "   - Responder preguntas sobre contenido visual\n",
    "   - An√°lisis comparativo de m√∫ltiples im√°genes\n",
    "\n",
    "3. **Flexibilidad**:\n",
    "   - Diferentes tipos de consultas\n",
    "   - M√∫ltiples formatos de imagen\n",
    "   - An√°lisis en varios idiomas\n",
    "\n",
    "### Casos de Uso Pr√°cticos:\n",
    "\n",
    "1. **E-commerce**:\n",
    "   - Descripci√≥n autom√°tica de productos\n",
    "   - Categorizaci√≥n de im√°genes\n",
    "   - B√∫squeda visual\n",
    "\n",
    "2. **Moderaci√≥n de Contenido**:\n",
    "   - Detecci√≥n de contenido inapropiado\n",
    "   - Clasificaci√≥n autom√°tica\n",
    "   - An√°lisis de cumplimiento\n",
    "\n",
    "3. **Accesibilidad**:\n",
    "   - Generaci√≥n de alt-text para im√°genes\n",
    "   - Descripci√≥n de gr√°ficos para usuarios con discapacidad visual\n",
    "   - Transcripci√≥n de texto en im√°genes\n",
    "\n",
    "4. **Educaci√≥n**:\n",
    "   - An√°lisis de diagramas y esquemas\n",
    "   - Explicaci√≥n de conceptos visuales\n",
    "   - Ayuda con tareas que incluyen im√°genes\n",
    "\n",
    "5. **Medicina**:\n",
    "   - An√°lisis preliminar de im√°genes m√©dicas (con disclaimers)\n",
    "   - Documentaci√≥n de casos\n",
    "   - Asistencia en diagn√≥stico (supervisado)\n",
    "\n",
    "6. **Real Estate**:\n",
    "   - Descripci√≥n autom√°tica de propiedades\n",
    "   - An√°lisis de caracter√≠sticas\n",
    "   - Generaci√≥n de listados\n",
    "\n",
    "7. **Control de Calidad**:\n",
    "   - Inspecci√≥n visual automatizada\n",
    "   - Detecci√≥n de defectos\n",
    "   - Verificaci√≥n de conformidad\n",
    "\n",
    "### Arquitectura para Producci√≥n:\n",
    "\n",
    "```python\n",
    "class ProductionVisionService:\n",
    "    def __init__(self):\n",
    "        self.agent = create_vision_agent()\n",
    "        self.cache = ImageAnalysisCache()\n",
    "        self.rate_limiter = RateLimiter(max_per_minute=60)\n",
    "    \n",
    "    async def analyze_image(self, img_bytes, question):\n",
    "        # Check cache\n",
    "        cache_key = hash_image(img_bytes)\n",
    "        if cached := self.cache.get(cache_key, question):\n",
    "            return cached\n",
    "        \n",
    "        # Rate limiting\n",
    "        await self.rate_limiter.acquire()\n",
    "        \n",
    "        # Analyze\n",
    "        result = await self.agent.run(build_message(img_bytes, question))\n",
    "        \n",
    "        # Cache result\n",
    "        self.cache.set(cache_key, question, result)\n",
    "        \n",
    "        return result\n",
    "```\n",
    "\n",
    "### Integraci√≥n con Otros Sistemas:\n",
    "\n",
    "1. **Pipelines de Datos**:\n",
    "   - Procesamiento batch de im√°genes\n",
    "   - ETL con enriquecimiento visual\n",
    "   - Generaci√≥n de metadatos\n",
    "\n",
    "2. **APIs REST**:\n",
    "   ```python\n",
    "   @app.post(\"/analyze-image\")\n",
    "   async def analyze_endpoint(file: UploadFile, question: str):\n",
    "       img_bytes = await file.read()\n",
    "       result = await vision_service.analyze_image(img_bytes, question)\n",
    "       return {\"analysis\": result}\n",
    "   ```\n",
    "\n",
    "3. **Eventos y Queues**:\n",
    "   - Procesamiento as√≠ncrono con Azure Service Bus\n",
    "   - Workflows con Azure Logic Apps\n",
    "   - Event-driven architecture\n",
    "\n",
    "### Futuro de Vision AI:\n",
    "\n",
    "- **Mayor precisi√≥n**: Modelos cada vez mejores\n",
    "- **Menor latencia**: Procesamiento m√°s r√°pido\n",
    "- **Menor costo**: Optimizaci√≥n de recursos\n",
    "- **M√°s modalidades**: Video, audio, 3D\n",
    "- **Mejor razonamiento**: Comprensi√≥n contextual profunda"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
