{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd058013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from agent_framework import (\n",
    "    AgentExecutor,\n",
    "    AgentExecutorRequest,\n",
    "    AgentExecutorResponse,\n",
    "    ChatMessage,\n",
    "    Executor,\n",
    "    RequestInfoEvent,\n",
    "    Role,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    WorkflowOutputEvent,\n",
    "    WorkflowRunState,\n",
    "    WorkflowStatusEvent,\n",
    "    handler,\n",
    "    response_handler,\n",
    ")\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c979cca4",
   "metadata": {},
   "source": [
    "## Modelos de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8549b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HumanFeedbackRequest:\n",
    "    \"\"\"Request message for human feedback in the guessing game.\"\"\"\n",
    "    prompt: str = \"\"\n",
    "    guess: int | None = None\n",
    "\n",
    "class GuessOutput(BaseModel):\n",
    "    \"\"\"Structured output from the AI agent.\"\"\"\n",
    "    guess: int\n",
    "\n",
    "print(\"‚úÖ Modelos de datos definidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f5523",
   "metadata": {},
   "source": [
    "## TurnManager Executor\n",
    "\n",
    "Coordina turnos entre agente y humano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3891cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurnManager(Executor):\n",
    "    \"\"\"Coordinates turns between the AI agent and human player.\"\"\"\n",
    "\n",
    "    def __init__(self, id: str | None = None):\n",
    "        super().__init__(id=id or \"turn_manager\")\n",
    "\n",
    "    @handler\n",
    "    async def start(self, _: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "        \"\"\"Start the game by asking the agent for an initial guess.\"\"\"\n",
    "        user = ChatMessage(Role.USER, text=\"Start by making your first guess.\")\n",
    "        await ctx.send_message(AgentExecutorRequest(messages=[user], should_respond=True))\n",
    "\n",
    "    @handler\n",
    "    async def on_agent_response(\n",
    "        self,\n",
    "        result: AgentExecutorResponse,\n",
    "        ctx: WorkflowContext,\n",
    "    ) -> None:\n",
    "        \"\"\"Handle the agent's guess and request human guidance.\"\"\"\n",
    "        text = result.agent_run_response.text or \"\"\n",
    "        last_guess = GuessOutput.model_validate_json(text).guess if text else None\n",
    "\n",
    "        prompt = (\n",
    "            f\"The agent guessed: {last_guess if last_guess is not None else text}. \"\n",
    "            \"Type one of: higher, lower, correct, or exit.\"\n",
    "        )\n",
    "        await ctx.request_info(\n",
    "            request_data=HumanFeedbackRequest(prompt=prompt, guess=last_guess),\n",
    "            response_type=str\n",
    "        )\n",
    "\n",
    "    @response_handler\n",
    "    async def on_human_feedback(\n",
    "        self,\n",
    "        original_request: HumanFeedbackRequest,\n",
    "        feedback: str,\n",
    "        ctx: WorkflowContext[AgentExecutorRequest, str],\n",
    "    ) -> None:\n",
    "        \"\"\"Continue the game or finish based on human feedback.\"\"\"\n",
    "        reply = feedback.strip().lower()\n",
    "        last_guess = original_request.guess\n",
    "\n",
    "        if reply == \"correct\":\n",
    "            await ctx.yield_output(f\"Guessed correctly: {last_guess}\")\n",
    "            return\n",
    "\n",
    "        user_msg = ChatMessage(\n",
    "            Role.USER,\n",
    "            text=f'Feedback: {reply}. Return ONLY a JSON object matching the schema {{\"guess\": <int 1..10>}}.',\n",
    "        )\n",
    "        await ctx.send_message(AgentExecutorRequest(messages=[user_msg], should_respond=True))\n",
    "\n",
    "print(\"‚úÖ TurnManager definido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccab826b",
   "metadata": {},
   "source": [
    "## Ejecutar el Juego Interactivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebcfd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    \"\"\"Funci√≥n principal que ejecuta el juego\"\"\"\n",
    "    \n",
    "    # Create the chat agent with structured output\n",
    "    chat_client = AzureOpenAIChatClient(\n",
    "        credential=AzureCliCredential(),\n",
    "        endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        deployment_name=os.getenv(\"MODEL\")\n",
    "    )\n",
    "    agent = chat_client.create_agent(\n",
    "        instructions=(\n",
    "            \"You guess a number between 1 and 10. \"\n",
    "            \"If the user says 'higher' or 'lower', adjust your next guess. \"\n",
    "            'You MUST return ONLY a JSON object: {\"guess\": <integer 1..10>}. '\n",
    "            \"No explanations or additional text.\"\n",
    "        ),\n",
    "        response_format=GuessOutput,\n",
    "    )\n",
    "\n",
    "    # Create workflow components\n",
    "    turn_manager = TurnManager(id=\"turn_manager\")\n",
    "    agent_exec = AgentExecutor(agent=agent, id=\"agent\")\n",
    "\n",
    "    # Build the workflow graph\n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(turn_manager)\n",
    "        .add_edge(turn_manager, agent_exec)\n",
    "        .add_edge(agent_exec, turn_manager)\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    # Execute the interactive workflow\n",
    "    await run_interactive_workflow(workflow)\n",
    "\n",
    "async def run_interactive_workflow(workflow):\n",
    "    \"\"\"Run the workflow with human-in-the-loop interaction.\"\"\"\n",
    "    pending_responses: dict[str, str] | None = None\n",
    "    completed = False\n",
    "    workflow_output: str | None = None\n",
    "\n",
    "    print(\"üéØ Number Guessing Game\")\n",
    "    print(\"Think of a number between 1 and 10, and I'll try to guess it!\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    while not completed:\n",
    "        stream = (\n",
    "            workflow.send_responses_streaming(pending_responses)\n",
    "            if pending_responses\n",
    "            else workflow.run_stream(\"start\")\n",
    "        )\n",
    "\n",
    "        events = [event async for event in stream]\n",
    "        pending_responses = None\n",
    "\n",
    "        requests: list[tuple[str, str]] = []\n",
    "        for event in events:\n",
    "            if isinstance(event, RequestInfoEvent) and isinstance(event.data, HumanFeedbackRequest):\n",
    "                requests.append((event.request_id, event.data.prompt))\n",
    "            elif isinstance(event, WorkflowOutputEvent):\n",
    "                workflow_output = str(event.data)\n",
    "                completed = True\n",
    "\n",
    "        if requests and not completed:\n",
    "            responses: dict[str, str] = {}\n",
    "            for req_id, prompt in requests:\n",
    "                print(f\"\\nü§ñ {prompt}\")\n",
    "                answer = input(\"üë§ Enter higher/lower/correct/exit: \").lower()\n",
    "\n",
    "                if answer == \"exit\":\n",
    "                    print(\"üëã Exiting...\")\n",
    "                    return\n",
    "                responses[req_id] = answer\n",
    "            pending_responses = responses\n",
    "\n",
    "    print(f\"\\nüéâ {workflow_output}\")\n",
    "\n",
    "print(\"‚úÖ Funciones definidas\")\n",
    "print(\"\\n‚ö†Ô∏è Ejecuta: await main()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26733b9e",
   "metadata": {},
   "source": [
    "## Ejecutar el Juego\n",
    "\n",
    "**Nota**: Este es un workflow interactivo. Deber√°s responder a los prompts del agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb70155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentar para ejecutar\n",
    "# await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c8e133",
   "metadata": {},
   "source": [
    "## Conclusi√≥n\n",
    "\n",
    "Este ejemplo demuestra:\n",
    "\n",
    "### 1. **Human-in-the-Loop Workflows**\n",
    "- `ctx.request_info()`: Solicitar input humano\n",
    "- `send_responses_streaming()`: Enviar respuestas de usuario\n",
    "- Flujo pausable y resumible\n",
    "\n",
    "### 2. **Workflow States**\n",
    "- `IN_PROGRESS_PENDING_REQUESTS`: Esperando respuestas\n",
    "- `IDLE_WITH_PENDING_REQUESTS`: Idle con requests pendientes\n",
    "- Gesti√≥n de estados para UX\n",
    "\n",
    "### 3. **Response Handlers**\n",
    "- `@response_handler`: Procesar respuestas humanas\n",
    "- Acceso al request original correlacionado\n",
    "- L√≥gica de continuaci√≥n basada en respuesta\n",
    "\n",
    "### Aplicaciones:\n",
    "- Aprobaciones en workflows\n",
    "- Validaci√≥n humana de decisiones\n",
    "- Resoluci√≥n de ambig√ºedades\n",
    "- Quality assurance loops"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
