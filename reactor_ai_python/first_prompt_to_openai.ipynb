{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a27875",
   "metadata": {},
   "source": [
    "## 1. Importar Librerías\n",
    "\n",
    "Importamos las bibliotecas necesarias para conectarnos a Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3461ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bb9104",
   "metadata": {},
   "source": [
    "## 2. Cargar Variables de Entorno\n",
    "\n",
    "Cargamos las credenciales desde el archivo `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58afbada",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "print(f\"Endpoint configurado: {os.getenv('AZURE_OPENAI_ENDPOINT')}\")\n",
    "print(f\"Modelo a usar: {os.getenv('MODEL')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1248ce97",
   "metadata": {},
   "source": [
    "## 3. Configurar Cliente de Azure OpenAI\n",
    "\n",
    "Creamos el cliente usando las credenciales y configuraciones del entorno. Configuramos `max_retries=5` para mayor robustez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f9b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = openai.AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_APIKEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "    max_retries=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e854253",
   "metadata": {},
   "source": [
    "## 4. Definir los Prompts\n",
    "\n",
    "Definimos dos partes del prompt:\n",
    "- **System prompt**: Define el comportamiento general del asistente\n",
    "- **User prompt**: La solicitud específica del usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49173b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Contestar de forma educada y en español\"\n",
    "user_prompt = \"Cuentame una historia de un gato y un perro que son amigos, en 100 palabras\"\n",
    "\n",
    "prompt = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt}, \n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "print(\"Prompt configurado:\")\n",
    "print(f\"Sistema: {system_prompt}\")\n",
    "print(f\"Usuario: {user_prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d6ab8",
   "metadata": {},
   "source": [
    "## 5. Realizar la Llamada a Azure OpenAI\n",
    "\n",
    "Enviamos el prompt al modelo y obtenemos la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e234201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = openai_client.chat.completions.create(\n",
    "    messages=prompt, \n",
    "    model=os.getenv(\"MODEL\")\n",
    ")\n",
    "\n",
    "print(\"\\n=== RESPUESTA DEL MODELO ===\")\n",
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19964552",
   "metadata": {},
   "source": [
    "## 6. Información Adicional sobre la Respuesta\n",
    "\n",
    "Podemos explorar otros detalles de la respuesta como tokens utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ebd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== ESTADÍSTICAS ===\")\n",
    "print(f\"Modelo usado: {result.model}\")\n",
    "print(f\"Tokens totales: {result.usage.total_tokens}\")\n",
    "print(f\"Tokens de prompt: {result.usage.prompt_tokens}\")\n",
    "print(f\"Tokens de respuesta: {result.usage.completion_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35be820",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Este ejemplo muestra:\n",
    "1. Configuración básica de Azure OpenAI con API key\n",
    "2. Estructura de mensajes con roles de sistema y usuario\n",
    "3. Llamada sincrónica al modelo\n",
    "4. Obtención de la respuesta y metadatos\n",
    "\n",
    "Este es el método más directo para interactuar con Azure OpenAI."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
