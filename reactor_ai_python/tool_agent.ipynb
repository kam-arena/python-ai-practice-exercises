{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54b71249",
   "metadata": {},
   "source": [
    "## 1. Importar Librerías\n",
    "\n",
    "Importamos las bibliotecas necesarias incluyendo `Annotated` y `Field` de Pydantic para definir herramientas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dcbd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "from typing import Annotated\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity.aio import get_bearer_token_provider\n",
    "from pydantic import Field\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f766ea",
   "metadata": {},
   "source": [
    "## 2. Cargar Variables de Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8514b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "model = os.getenv(\"MODEL\")\n",
    "\n",
    "print(f\"Endpoint: {endpoint}\")\n",
    "print(f\"Modelo: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95b8de1",
   "metadata": {},
   "source": [
    "## 3. Configurar Cliente de OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6229ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAIChatClient(\n",
    "    base_url=os.getenv(\"AZURE_OPENAI_ENDPOINT\") + \"/openai/v1/\",\n",
    "    api_key=get_bearer_token_provider(\n",
    "        DefaultAzureCredential(), \n",
    "        \"https://cognitiveservices.azure.com/.default\"\n",
    "    ),\n",
    "    model_id=os.getenv(\"MODEL\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d8311",
   "metadata": {},
   "source": [
    "## 4. Definir la Herramienta del Clima\n",
    "\n",
    "Esta función simula una consulta de clima. Los parámetros usan `Annotated` con `Field` para proporcionar descripciones que el modelo LLM usará para entender cuándo y cómo llamar a la función.\n",
    "\n",
    "**Nota**: Esta es una simulación. En producción, esto llamaría a una API real de clima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(\n",
    "    city: Annotated[str, Field(description=\"City name, spelled out fully\")],\n",
    ") -> dict:\n",
    "    \"\"\"Simula una consulta de clima para una ciudad.\"\"\"\n",
    "    print(f\"Getting weather for {city}\")\n",
    "    \n",
    "    # Simulación aleatoria\n",
    "    if random.random() < 0.5:\n",
    "        return {\"temperature\": 72, \"description\": \"Sunny\"}\n",
    "    else:\n",
    "        return {\"temperature\": 60, \"description\": \"Rainy\"}\n",
    "\n",
    "print(\"Herramienta get_weather definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ee3ba",
   "metadata": {},
   "source": [
    "## 5. Crear el Agente con Herramienta\n",
    "\n",
    "Creamos un agente y le pasamos la herramienta `get_weather`. El agente decidirá automáticamente cuándo usar esta herramienta basándose en la consulta del usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38031ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatAgent(\n",
    "    chat_client=client, \n",
    "    instructions=\"You're an informational agent. Answer questions cheerfully.\", \n",
    "    tools=[get_weather]\n",
    ")\n",
    "\n",
    "print(\"Agente creado con herramienta de clima\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31656071",
   "metadata": {},
   "source": [
    "## 6. Ejecutar Consulta de Clima\n",
    "\n",
    "Cuando preguntamos sobre el clima, el agente:\n",
    "1. Reconoce que necesita información del clima\n",
    "2. Llama automáticamente a la función `get_weather`\n",
    "3. Usa el resultado para responder al usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    print(\"\\n=== Consultando clima ===\")\n",
    "    response = await agent.run(\"Whats weather today in sf?\")\n",
    "    print(f\"\\nRespuesta del agente:\\n{response}\")\n",
    "\n",
    "# Ejecutar en entorno Jupyter\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08156a",
   "metadata": {},
   "source": [
    "## 7. Probar Consultas sin Herramienta\n",
    "\n",
    "El agente también puede responder preguntas que no requieren herramientas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6537b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_general_question():\n",
    "    print(\"\\n=== Pregunta general ===\")\n",
    "    response = await agent.run(\"What is the capital of France?\")\n",
    "    print(f\"\\nRespuesta del agente:\\n{response}\")\n",
    "\n",
    "await test_general_question()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a148fdd9",
   "metadata": {},
   "source": [
    "## 8. Múltiples Consultas de Clima\n",
    "\n",
    "Podemos hacer varias consultas sobre diferentes ciudades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_multiple_cities():\n",
    "    cities = [\"Tokyo\", \"London\", \"New York\"]\n",
    "    \n",
    "    print(\"\\n=== Consultando clima en múltiples ciudades ===\")\n",
    "    for city in cities:\n",
    "        print(f\"\\n--- {city} ---\")\n",
    "        response = await agent.run(f\"What's the weather like in {city}?\")\n",
    "        print(f\"Respuesta: {response.text}\")\n",
    "\n",
    "await test_multiple_cities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d431a940",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Este ejemplo demuestra:\n",
    "1. **Function Calling**: El modelo LLM puede llamar automáticamente a funciones Python\n",
    "2. **Anotaciones de tipo**: Uso de `Annotated` y `Field` para documentar parámetros\n",
    "3. **Decisión automática**: El agente decide cuándo usar herramientas\n",
    "4. **Integración natural**: El resultado de la función se integra en la respuesta\n",
    "\n",
    "Aplicaciones prácticas:\n",
    "- Consulta de APIs externas (clima, noticias, stocks)\n",
    "- Acceso a bases de datos\n",
    "- Cálculos complejos\n",
    "- Interacción con sistemas externos\n",
    "\n",
    "El framework maneja automáticamente la serialización/deserialización de datos entre el modelo y las funciones."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
